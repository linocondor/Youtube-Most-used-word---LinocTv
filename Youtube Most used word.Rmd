---
title: "Youtube Tending Videos - Most used Word"
output: html_notebook
---

This is a tutorial of the library from quanteda.

We are going to search for the most used word in Youtube trending videos comments from US and UK

Github:
https://github.com/linocondor/Youtube-Most-used-word---LinocTv

Dataset from Kaggle:
https://lnkd.in/e66ir7S
 
<h3>Install libraries</h3>
```{r}
#install libraries
install.packages("quanteda")
install.packages("quanteda.textplots")

```

<h3>Initiate libraries</h3>
```{r}
#Initiate libraries
library(quanteda)
library(quanteda.textplots)


```

<h3>Calling the Data for US and UK</h3>
```{r}

data_US <- UScomments
data_UK <- GBcomments

#see data
head(data_US)
#head(data_UK)

```
<h3>Creating Corpus for each data</h3>
```{r}
data_US_corpus <- corpus(data_US, text_field = "comment_text")
data_UK_corpus <- corpus(data_UK, text_field = "comment_text")

#see a summary
summary(data_US_corpus, n = 5)
#summary(data_UK_corpus, n = 5)
```
<h3>Creating Document Feature Matrix</h3>
```{r}
# make a dfm, removing stopwords, numbers and applying stemming
matrix_comments_US <- dfm(data_US_corpus, remove = stopwords("english"), 
    stem = TRUE, remove_punct = TRUE, remove_numbers = TRUE)

matrix_comments_UK <- dfm(data_UK_corpus, remove = stopwords("english"), 
    stem = TRUE, remove_punct = TRUE, remove_numbers = TRUE)

matrix_comments_US[1:5, 1:10]
matrix_comments_UK[1:5, 1:10]
```

<h3>Creating US PLOT: WORDCLOUD</h3>
```{r}
#wordcloud
set.seed(100)

textplot_wordcloud(matrix_comments_US, min_count = 1000, random_order = FALSE, rotation = 0.25, 
    color = RColorBrewer::brewer.pal(10, "Dark2"))
```
<h3>Creating UK PLOT: WORDCLOUD</h3>
```{r}
#wordcloud
set.seed(100)

textplot_wordcloud(matrix_comments_UK, min_count = 1000, random_order = FALSE, rotation = 0.25, 
    color = RColorBrewer::brewer.pal(8, "Dark2"))
```
